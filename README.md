# ğŸ“Š View Enterprise - Pipeline de Processamento de Dados Empresariais

---

## ğŸ“„ Abstract

**View Enterprise** is a distributed data orchestration and processing system designed to extract, transform, and load business information from two public APIs. Automated by an Airflow DAG, the system queries data daily from DynamoDB, processes it using PySpark within an AWS Glue Job, stores the partitioned results in an S3 bucket, and delivers analytical visualizations through dashboards in Amazon QuickSight.

---

## ğŸŒ VisÃ£o Geral

O projeto foi desenvolvido com o objetivo de oferecer um fluxo automatizado de coleta e enriquecimento de dados de CNPJs, permitindo anÃ¡lises diÃ¡rias com atualizaÃ§Ã£o contÃ­nua dos dados empresariais brasileiros.

### ğŸš€ Como funciona:
- Uma **DAG PySpark** executada via **Airflow** roda diariamente;
- Ela consulta o **DynamoDB** e verifica se existem CNPJs associados ao dia do processamento;
- Se houver, realiza o fetch dos dados a partir da **Receita Federal** e da **Brasil API**;
- Os dados sÃ£o integrados, transformados e salvos no **S3 em formato Parquet particionado**;
- A visualizaÃ§Ã£o dos dados Ã© feita atravÃ©s de **dashboards interativos no Amazon QuickSight**.

---

## ğŸ§° Stacks e Tecnologias Utilizadas

| Tecnologia     | Finalidade                                                |
|----------------|-----------------------------------------------------------|
| **PySpark**    | Processamento paralelo e transformaÃ§Ãµes de dados          |
| **Airflow**    | Agendamento e orquestraÃ§Ã£o de DAGs                        |
| **Glue Job**   | ExecuÃ§Ã£o de cÃ³digo PySpark na AWS                         |
| **DynamoDB**   | Armazenamento da lista de CNPJs por data de execuÃ§Ã£o      |
| **Amazon S3**  | Armazenamento de dados processados (formato Parquet)      |
| **QuickSight** | VisualizaÃ§Ã£o de dados e geraÃ§Ã£o de dashboards analÃ­ticos  |

---

## ğŸ“ˆ VisualizaÃ§Ãµes no QuickSight

As anÃ¡lises disponÃ­veis no painel incluem:

- EvoluÃ§Ã£o do **capital social** das empresas ao longo do tempo;
- Lista das **empresas mais antigas**;
- **DistribuiÃ§Ã£o por paÃ­s**, destacando o paÃ­s com mais empresas cadastradas.

---

## ğŸ“¦ Estrutura Final dos Dados

ApÃ³s o processamento, o resultado final Ã© armazenado com a seguinte estrutura de dados:

```json
{
  "cnpj": "string",                        
  "pais": "string",                        
  "atividade_principal": { ... },         
  "nome": "string",                        
  "atividade_secundaria": { ... },        
  "telefone": "string",                   
  "data_inicio_atividade": "string",      
  "cnae_fiscal_descricao": "string",     
  "capital_social": number              
}
```

---

## ğŸ—‚ï¸ OrganizaÃ§Ã£o do Projeto

```bash
view-enterprises/
â”œâ”€â”€ artifacts
â”œâ”€â”€ README.md
â””â”€â”€ src
    â”œâ”€â”€ devutils
    â”œâ”€â”€ etl
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ main.py
    â”œâ”€â”€ __pycache__
    â”œâ”€â”€ scoped_context.py
    â”œâ”€â”€ service
    â””â”€â”€ tests
```

---

## ğŸ› ï¸ Como Executar

1. Configure suas credenciais AWS (S3, Glue, DynamoDB e QuickSight).
2. Ajuste a DAG no Airflow (`dag_view_enterprise.py`) com os parÃ¢metros do ambiente.
3. Rode o Airflow e agende a DAG para execuÃ§Ã£o diÃ¡ria.
4. Os dados processados ficarÃ£o salvos no S3, disponÃ­veis para anÃ¡lise via QuickSight.

---

## ğŸ”® Futuras EvoluÃ§Ãµes

- ValidaÃ§Ã£o automÃ¡tica de CNPJs antes do processamento;
- Versionamento dos datasets com Delta Lake;
- Enriquecimento com novas fontes de dados (como LinkedIn ou Receita estadual);
- Alertas por e-mail em caso de falha no pipeline.

---

## ğŸ“¬ Contato do Desenvolvedor

Desenvolvido com dedicaÃ§Ã£o por **Guilherme OliBr**  
ğŸ“§ **Email:** guilherme.oliver12@gmail.com 
ğŸŒ **GitHub:** [github.com/Guilherm12122](https://github.com/Guilherm12122)

---
